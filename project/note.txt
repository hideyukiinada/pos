Notes


CuDNNLSTM vs LSTM Performance Comparison
========================================
Date:June 4, 2019

How to import
-------------
from keras.layers import LSTM
from keras.layers import CuDNNLSTM as LSTM

Two epoch performance
---------------------
LSTM
 - 189s - loss: 0.3703 - categorical_accuracy: 0.9371
 - 188s - loss: 0.2083 - categorical_accuracy: 0.9455

CuDNNLSTM
 - 34s - loss: 0.3776 - categorical_accuracy: 0.9365
 - 33s - loss: 0.2059 - categorical_accuracy: 0.9460

Loss data
=========

Brown corpus
------------

1. Without embedding
20 epochs

# Run 1
 43s 824us/step -
 loss: 0.1462 - categorical_accuracy: 0.9599 - val_loss: 0.1210 - val_categorical_accuracy: 0.9673

# Run 2
 42s 822us/step
 loss: 0.1441 - categorical_accuracy: 0.9603 - val_loss: 0.1204 - val_categorical_accuracy: 0.9670

2. With embedding
20 epochs

# Run 3
45s 870us/step
loss: 0.0052 - categorical_accuracy: 0.9984 - val_loss: 0.0202 - val_categorical_accuracy: 0.9950


ConLL2002
------------

Without embedding
-----------------

Data shape:
Size of training set: 32085
Shape of training set: (32085, 2000, 1)
Size of test set: 3566
Number of unique words: 65461
Number of unique tags: 73
Weights path: result/conll2002_weights.h5
Train on 32085 samples, validate on 3566 samples

20 epochs

# run 1
47s 1ms/step -
loss: 0.0173 - categorical_accuracy: 0.9948 - val_loss: 0.0132 - val_categorical_accuracy: 0.9959